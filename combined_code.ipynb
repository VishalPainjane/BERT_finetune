{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320ac011",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "login(HF_TOKEN)\n",
    "\n",
    "squad = load_dataset(\"squad\", split=\"train[:5000]\")\n",
    "squad = squad.train_test_split(test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f67d344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3f09c1853eb4ab39ffd18c23ee3d309",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nikhi\\OneDrive\\Documents\\GitHub\\BERT_finetune\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\nikhi\\.cache\\huggingface\\hub\\models--distilbert--distilbert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "452203fc1ab14c978042f6560fe1d287",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67da12f1c8ae447f8ddcf6a45d2ac6b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "496fe7fb14ca47638fc796c6c61951d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566740b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=384,\n",
    "        truncation=\"only_second\",\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    answers = examples[\"answers\"]\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        answer = answers[i]\n",
    "        start_char = answer[\"answer_start\"][0]\n",
    "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43cefce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df9389f8ebd248faa198db607df3471f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1f0c33f2d3f41d6abc625b5e664ed46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_squad = squad.map(preprocess_function, batched=True, remove_columns=squad[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29a5d8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DefaultDataCollator\n",
    "\n",
    "data_collator = DefaultDataCollator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "886a1d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c0a6fd346364eebb9b09f669fc76e0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"distilbert/distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9e1a10e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='750' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [750/750 11:49:14, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.302172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.749100</td>\n",
       "      <td>1.631831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.749100</td>\n",
       "      <td>1.572548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(MaxRetryError(\"HTTPSConnectionPool(host='hf-hub-lfs-us-east-1.s3-accelerate.amazonaws.com', port=443): Max retries exceeded with url: /repos/54/2d/542d6d6c211d5f19920153c852547a742042ce802f5700875d0ea5155afb412f/ac9deb2985330d1e5983664c81fafd1563537822bb4d700bfa23013da94faac3?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIA2JU7TKAQLC2QXPN7%2F20250608%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250608T185132Z&X-Amz-Expires=86400&X-Amz-Signature=92b56db8c5486b898e9d9f8824449d35076ae6a87acd2e2d3cf92f85aaf5a061&X-Amz-SignedHeaders=host&partNumber=1&uploadId=YkutSxr3g8hOejQlQTcuplc1mlgxatjFgAkRqa3lTFL95Nb1NKkN3qT5BMbXYramHLIWSqnWYwLbExy.Ug_xi6azgBaLVXW9tP3LKaF8hMJJmTRGvk1zAPQRC0zR5DAT&x-id=UploadPart (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:2406)')))\"), '(Request ID: 208e685c-7582-4fd7-8e55-65a88a2e998b)')' thrown while requesting PUT https://hf-hub-lfs-us-east-1.s3-accelerate.amazonaws.com/repos/54/2d/542d6d6c211d5f19920153c852547a742042ce802f5700875d0ea5155afb412f/ac9deb2985330d1e5983664c81fafd1563537822bb4d700bfa23013da94faac3?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIA2JU7TKAQLC2QXPN7%2F20250608%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250608T185132Z&X-Amz-Expires=86400&X-Amz-Signature=92b56db8c5486b898e9d9f8824449d35076ae6a87acd2e2d3cf92f85aaf5a061&X-Amz-SignedHeaders=host&partNumber=1&uploadId=YkutSxr3g8hOejQlQTcuplc1mlgxatjFgAkRqa3lTFL95Nb1NKkN3qT5BMbXYramHLIWSqnWYwLbExy.Ug_xi6azgBaLVXW9tP3LKaF8hMJJmTRGvk1zAPQRC0zR5DAT&x-id=UploadPart\n",
      "Retrying in 1s [Retry 1/5].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=750, training_loss=2.297464111328125, metrics={'train_runtime': 42564.8138, 'train_samples_per_second': 0.282, 'train_steps_per_second': 0.018, 'total_flos': 1175877900288000.0, 'train_loss': 2.297464111328125, 'epoch': 3.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"my_awesome_qa_model\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_squad[\"train\"],\n",
    "    eval_dataset=tokenized_squad[\"test\"],\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114f1050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53084edcc31e4167b9bddd5a94487064",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/4000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdd54b8ad54a4a6f837a8f274b55f0a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ab12212985645588b2be74219eae57e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/4000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8231068ccf054192a32fc29e8675afe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All components saved successfully in the 'model' folder!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"model\", exist_ok=True)\n",
    "\n",
    "tokenizer.save_pretrained(\"model/tokenizer\")\n",
    "model.save_pretrained(\"model/model\")\n",
    "squad.save_to_disk(\"model/squad_dataset\")\n",
    "tokenized_squad.save_to_disk(\"model/tokenized_squad_dataset\")\n",
    "trainer.save_model(\"model/trainer_model\")\n",
    "\n",
    "print(\"All components saved successfully in the 'model' folder!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cbcaa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 06:40]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "eval_loss: 1.5725481510162354\n",
      "eval_runtime: 402.3968\n",
      "eval_samples_per_second: 2.485\n",
      "eval_steps_per_second: 0.157\n",
      "epoch: 3.0\n"
     ]
    }
   ],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "\n",
    "print(\"Evaluation Results:\")\n",
    "for key, value in eval_results.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed338850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What interface feature did Apple unsuccessfully try to patent?\n",
      "Context: Apple's application to the United States Patent and Trademark Office for a patent on \"rotational user inputs\", as used on the iPod interface, received a third \"non-final rejection\" (NFR) in August 200...\n",
      "Predicted Answer: \n",
      "Ground Truth Answer: rotational user inputs\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "sample_data = squad[\"test\"][0]\n",
    "question = sample_data[\"question\"]\n",
    "context = sample_data[\"context\"]\n",
    "\n",
    "inputs = tokenizer(question, context, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "answer_start_index = outputs.start_logits.argmax()\n",
    "answer_end_index = outputs.end_logits.argmax()\n",
    "\n",
    "predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
    "predicted_answer = tokenizer.decode(predict_answer_tokens, skip_special_tokens=True)\n",
    "\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Context: {context[:200]}...\")\n",
    "print(f\"Predicted Answer: {predicted_answer}\")\n",
    "print(f\"Ground Truth Answer: {sample_data['answers']['text'][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fb53f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COMPARISON: BEFORE vs AFTER FINE-TUNING ===\n",
      "\n",
      "BEFORE FINE-TUNING (Original DistilBERT):\n",
      "Predicted Answer: 'the ipod line, which creative technology dubbed the \" zen patent \", granted on august 9, 2005. on may 15, 2006, creative filed another suit against apple with the united states district court'\n",
      "Start/End positions: 94/132\n",
      "\n",
      "==================================================\n",
      "\n",
      "AFTER FINE-TUNING (Our trained model):\n",
      "Predicted Answer: 'inputs \", as used on the ipod interface, received a third \" non - final rejection \" ( nfr ) in august 2005. also in august 2005, creative technology, one of apple ' s main rivals in the mp3 player market, announced that it held a patent on part of the music'\n",
      "Start/End positions: 31/89\n",
      "\n",
      "==================================================\n",
      "\n",
      "GROUND TRUTH:\n",
      "Correct Answer: 'rotational user inputs'\n",
      "Question: What interface feature did Apple unsuccessfully try to patent?\n",
      "Context snippet: ...5. Also in August 2005, Creative Technology, one of Apple's main rivals in the MP3 player market, announced that it held a patent on part of the music selection interface used by the iPod line, which ...\n"
     ]
    }
   ],
   "source": [
    "original_model = AutoModelForQuestionAnswering.from_pretrained(\"distilbert/distilbert-base-uncased\")\n",
    "\n",
    "\n",
    "print(\"BEFORE FINE-TUNING (Original DistilBERT):\")\n",
    "with torch.no_grad():\n",
    "    original_outputs = original_model(**inputs)\n",
    "\n",
    "original_answer_start = original_outputs.start_logits.argmax()\n",
    "original_answer_end = original_outputs.end_logits.argmax()\n",
    "\n",
    "if original_answer_start > original_answer_end:\n",
    "    original_answer_start, original_answer_end = original_answer_end, original_answer_start\n",
    "\n",
    "original_answer_tokens = inputs.input_ids[0, original_answer_start : original_answer_end + 1]\n",
    "original_predicted_answer = tokenizer.decode(original_answer_tokens, skip_special_tokens=True)\n",
    "\n",
    "print(f\"Predicted Answer: '{original_predicted_answer}'\")\n",
    "print(f\"Start/End positions: {original_answer_start}/{original_answer_end}\")\n",
    "\n",
    "print(\"AFTER FINE-TUNING (Our trained model):\")\n",
    "fine_tuned_start = answer_start_index\n",
    "fine_tuned_end = answer_end_index\n",
    "\n",
    "if fine_tuned_start > fine_tuned_end:\n",
    "    fine_tuned_start, fine_tuned_end = fine_tuned_end, fine_tuned_start\n",
    "\n",
    "fine_tuned_tokens = inputs.input_ids[0, fine_tuned_start : fine_tuned_end + 1]\n",
    "fine_tuned_answer = tokenizer.decode(fine_tuned_tokens, skip_special_tokens=True)\n",
    "\n",
    "print(f\"Predicted Answer: '{fine_tuned_answer}'\")\n",
    "print(f\"Start/End positions: {fine_tuned_start}/{fine_tuned_end}\")\n",
    "\n",
    "print(\"GROUND TRUTH:\")\n",
    "print(f\"Correct Answer: '{sample_data['answers']['text'][0]}'\")\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Context snippet: ...{context[200:400]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddacbab9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
